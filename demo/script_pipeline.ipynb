{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Script pipeline",
   "id": "ea63d31c0f4757b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Before starting\n",
    "\n",
    "Collect your videos in MP4 format, give them a unique commercial ID (make sure their names are the same of the corresponding `commerical_id` values) and put them in the `videos` folder.\n",
    "\n",
    "Then fill in the CSV file `initial_data/commercials_initial_metadata.csv` with the metadata of each video:\n",
    "\n",
    "- `commercial_id`\n",
    "- `title`\n",
    "- `brand`\n",
    "- `nice_class`\n",
    "- `product_type_key`\n",
    "- `year`\n",
    "- `lustrum`\n",
    "- `source`"
   ],
   "id": "b9eff5faa528c0c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Color and Thumb Extraction\n",
    "\n",
    "- Analyze each video and collects new data (`avg_frame_rate`, `aspect_ratio`), add them to `commercials_initial_metadata.csv` and save it as `general/commercials.csv`.\n",
    "- Split each video in “scenes”.\n",
    "- For each scene, extract the representative median frame and save it in small size (with height of 180 px), in WEBP format, in a folder named after the `commercial_id` in the `thumbnails` folder.\n",
    "- From each median frame, extract a color palette of maximum 32 colours and save them in a CSV file named\n",
    "  `general/commercial_palettes.csv` with these data:\n",
    "    - `commercial_id`\n",
    "    - `scene`: the progressive number ID of the scene.\n",
    "    - `scene_size`: the scene duration measured in frames.\n",
    "    - `start_frame`: the initial frame number of the scene.\n",
    "    - `end_frame`: the final frame number of the scene.\n",
    "    - `hex_code`: the hexadecimal representation of the original colour extracted.\n",
    "    - `frequency_within_the_scene`: the frequency of the original colour in the scene.\n",
    "    - `closest_color_ext_pal`: the closet colour from the extended palette.\n",
    "    - `closest_color_ess_pal`: the closet colour from the essential palette.\n",
    "    - `closest_color_bas_pal`: the closet colour from the basic palette.\n",
    "    - `scene_size_norm`: the normalized scene size.\n",
    "    - `frequency_within_the_commercial`: the frequency of the original colour within the video (`frequency_within_the_scene` × `scene_size_norm`)\n",
    "    - `tf`: the term frequency of the `closest_color_ext_pal` value in the video.\n",
    "- save the info about each scene detected in each video into `general/scenes.csv`."
   ],
   "id": "1ac2a1d0907e0643"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-28T15:15:28.342901Z"
    }
   },
   "cell_type": "code",
   "source": "%run '1_color_and_thumb_extraction.py'",
   "id": "790e048a1dc84074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Reference Palette Idf Calculation\n",
    "\n",
    "Calculate the idfs (Inverse Document Frequencies) of each color for each reference palette and save them as:\n",
    "- `colors/basic_palette_idfs.csv`\n",
    "- `colors/essential_palette_idfs.csv`\n",
    "- `colors/extended_palette_idfs.csv`"
   ],
   "id": "38a8ef22f4470b0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%run '2_ref_palette_idf_calculation.py'",
   "id": "3e3cb35e6f77600d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Audio Feature Extraction\n",
    "\n",
    "Export the 19 audio features of each video in the folder `audio/features`."
   ],
   "id": "d7a1e50806b31c97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%run '3_audio_feature_extraction.py'",
   "id": "e1cfb361785b0047",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Audio Transcription and Lemmatization\n",
    "\n",
    "- Find the “Speech” presence in each video, save it as `audio/speech_class_confidence_score.csv` and transcribe the found speech. All transcriptions are saved in `text/transcriptions.csv`\n",
    "- Lemmatize each transcription and save lemmas (alphabetically ordered by video) as `text/lemmas.csv`.\n",
    "- Calculate the tf-idf values for each lemma and update `text/lemmas.csv`."
   ],
   "id": "c09b78702f23e5e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%run '4_audio_transcription_and_lemmatization.py'",
   "id": "49b7ff68f2c1dfb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Finally\n",
    "\n",
    "You can use `text/transcriptions.csv` as input for further text analysis (e.g. LIWC analysis)."
   ],
   "id": "631ec7d9f129628f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "553c840eaca36f1e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
